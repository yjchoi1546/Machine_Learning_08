{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec6fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da604d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"data/ratings.csv\")\n",
    "movies = pd.read_csv(\"data\\movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ac06da",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = pd.merge(ratings,movies,on='movieId')\n",
    "movie_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e960910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_user = movie_ratings.pivot_table(index='userId', columns='title', values='rating')\n",
    "title_user = title_user.fillna(0)\n",
    "\n",
    "rating_matrix = title_user.T # 행과 열 바꾸기(전치행렬)\n",
    "rating_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbbec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_sim = cosine_similarity(rating_matrix,rating_matrix)\n",
    "item_sim_df = pd.DataFrame(data=item_sim,index=rating_matrix.index, columns=rating_matrix.index) # numpy array에 바로 집어 넣은 것\n",
    "item_sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8bbff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_sim_df['African Queen, The (1951)'].sort_values(ascending=False)[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f1c6d7",
   "metadata": {},
   "source": [
    "# 서프라이즈 라이브러리 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1824ee",
   "metadata": {},
   "source": [
    "설치 안되면, Microsoft C++ Build Tools - Visual Studio -> 여기서 Tool 설치\n",
    "\n",
    "<numpy 에러 발생시>\n",
    "uv pip uninstall numpy\n",
    "uv pip install \"numpy<2\"\n",
    "\n",
    "아니면 파이썬 버전 3.10 으로 다운 그레이드 하고 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d31f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import Reader\n",
    "from surprise.dataset import DatasetAutoFolds\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b114e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"data/ratings.csv\")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63286939",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.to_csv(\"data/ratings_nohead.csv\", index= False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b90b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec45155",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912838a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(line_format = 'user item rating timestamp',sep=',',rating_scale=(0.5,5)) # line_format: csv 파일의 컬럼명 지정, sep 을 넣어주는 이유는 ,로 구분이 안되어있는 것들이 있어서.\n",
    "#  rating_scale=(0.5,5) -> 크기가 0.5가 최소 5가 최대\n",
    "data_folds = DatasetAutoFolds(ratings_file='data/ratings_nohead.csv',reader=reader) # ratings_file : 내가 학습시킬 파일\n",
    "trainset = data_folds.build_full_trainset() #학습용 100%로 하겠다\n",
    "\n",
    "# 모델 생성\n",
    "model = SVD(n_factors=50, random_state=42) #적절한 n_factors 를 제공해주는 것이 좋음.\n",
    "model.fit(trainset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ac32d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict('9','3') # 9번:userid 유저의 3번 영화\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573f7fd",
   "metadata": {},
   "source": [
    "## 유저가 영화를 봤는 지 안봤는 지 확인\n",
    "### 전체 영화 - 본 영화 = 안 본 영화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6a9e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('data/movies.csv')\n",
    "\n",
    "def get_unseen_surprise(userid):\n",
    "    return list(set(movies['movieId']) - set(ratings[ratings['userId'] == userid]['movieId']))\n",
    "\n",
    "unseen_movies = get_unseen_surprise(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c9a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = []\n",
    "\n",
    "for movieid in unseen_movies:\n",
    "    result = model.predict('9',str(movieid))\n",
    "    data = {}  #{'id':1, 'rating':3.5, 'title':'Avatar'}\n",
    "    data['id'] = result.iid # 내가 평점을 매긴 id\n",
    "    data['rating'] = result.est \n",
    "    data['title'] = movies[movies['movieId']==int(result.iid)]['title'].iloc[0]\n",
    "    pred_result.append(data)\n",
    "\n",
    "result_df = pd.DataFrame(pred_result) \n",
    "result_df.sort_values('rating',ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0151940",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[result_df['title']=='African Queen, The (1951)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2eb204",
   "metadata": {},
   "source": [
    "# autoviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ccd88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9fd0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/heart.csv\")\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from autoviz.AutoViz_Class import AutoViz_Class #Auto ML 쓰는 이유 : 젤 좋은 모델 알기 위해서.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "av = AutoViz_Class()\n",
    "\n",
    "av.AutoViz(\n",
    "    filename = '',\n",
    "    dfte=df,\n",
    "    depVar='target',\n",
    "    verbose=1,\n",
    "    max_rows_analyzed=df.shape[0],\n",
    "    max_cols_analyzed=df.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2491e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_data = df.pop('target') # 함부로 쓰면 안됨. 없어지기 때문에\n",
    "X_data = df\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_data,y_data,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455d8f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58696fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "lcf_model = LazyClassifier(verbose=0, ignore_warnings=True,custom_metric=None)\n",
    "models,predictions = lcf_model.fit(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c4cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7165dc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/heart.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61133982",
   "metadata": {},
   "source": [
    "# Optuna 사용 -> 최적화된 하이퍼 파라미터를 설정해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df81986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data = fetch_california_housing()\n",
    "\n",
    "X_data = data.data\n",
    "y_data = data.target\n",
    "\n",
    "X_train,X_test,y_train, y_test = train_test_split(X_data,y_data,test_size=0.2,random_state=42) # 모델이 랜덤 값에 영향을 받기 때문에 고정해놔야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd191b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    model_type = trial.suggest_categorical(\"model\",['RandomForest','GradientBoost','XGBoost']) # 순서대로 지정해준다는 뜻\n",
    "\n",
    "    if model_type==\"RandomForest\":\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=trial.suggest_int('n_estimators',100,1500), # int형의 값을 suggest 하겠다. 100부터 1500 까지\n",
    "            max_depth = trial.suggest_int('max_depth',3,50),\n",
    "            min_samples_split = trial.suggest_int('min_samples_split',2,10),\n",
    "            random_state = 42\n",
    "        )\n",
    "    elif model_type==\"GradientBoost\":\n",
    "        model = GradientBoostingRegressor(\n",
    "        n_estimators=trial.suggest_int('n_estimators',100,1500), # int형의 값을 suggest 하겠다. 100부터 1500 까지\n",
    "        max_depth = trial.suggest_int('max_depth',3,50),\n",
    "        learning_rate = trial.suggest_float('learning_rate',0.01,0.3),  #learning rate 값 : 0.01 => 딥러닝에선 영향을 많이 끼친다.\n",
    "        random_state = 42\n",
    "        )\n",
    "    elif model_type==\"XGBoost\":\n",
    "        model = XGBRegressor(\n",
    "        n_estimators = trial.suggest_int('n_estimators',100,1500), # int형의 값을 suggest 하겠다. 100부터 1500 까지\n",
    "        max_depth = trial.suggest_int('max_depth',3,50),\n",
    "        learning_rate = trial.suggest_float('learning_rate',0.01,0.3),  #learning rate 값 : 0.01 => 딥러닝에선 영향을 많이 끼친다.\n",
    "        subsample = trial.suggest_float('subsample',0.5,1.0),\n",
    "        random_state = 42\n",
    "        )\n",
    "\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return r2_score(y_test,y_pred)\n",
    "    \n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\") # 결과값이 커지는 방향으로 파인 튜닝해라\n",
    "study.optimize( objective, n_trials=50) # n_trials은 50번 학습해라.\n",
    "\n",
    "print(\"최고의 모델 : \",study.best_params['model'])\n",
    "print('최고의 파라미터 : ',study.best_params)\n",
    "print('최고 스코어 : ',study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20270a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 예시\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import joblib\n",
    "\n",
    "# # 데이터 준비 및 모델 학습\n",
    "# X, y = load_iris(return_X_y=True)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# model = RandomForestClassifier()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # 모델 저장\n",
    "# joblib.dump(model, 'model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57524b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = joblib.load('model.plk') # -> 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c0b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dee214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이렇게 저장하면 됨\n",
    "# model = GradientBoostingRegressor(\n",
    "#             n_estimators=100,\n",
    "#             max_depth=3,\n",
    "#             learning_rate=0.01,\n",
    "#             random_state=42)\n",
    "\n",
    "# model.fit(X_train)\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(model,'model/best_GB_Regressor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6501893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "loaded_model = joblib.load('model/best_GB_Regressor.pkl')\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5324ae2e",
   "metadata": {},
   "source": [
    "## pickle 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea33e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle 사용\n",
    "# 모델 저장\n",
    "import pickle\n",
    "\n",
    "with open('best_GB_Regressor.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e1b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "\n",
    "with open('best_GB_Regressor.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_08",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
